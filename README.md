# TapCanvas

**可视化 AI 创作画布（零 GPU）**

## 📝 简介

TapCanvas 项目主要针对 Sora 2 做了专门的画布能力优化，支持直接 Remix 链式调用，实现多账号共享，让用户能够完美留下自己的创作痕迹。但我们的远不止于此：

**🎨 创新的可视化工作流**

- 首创将复杂AI创作流程转化为直观的节点连线操作
- 支持文生图→图生视频→视频合成的完整创作链路
- 智能类型匹配系统，自动防止错误连接，让创作更可靠

**⚡ 强大的画布交互体验**

- 基于React Flow的高性能渲染，支持复杂工作流流畅操作
- 独有的组聚焦模式，让大型项目也能清晰管理
- 智能辅助连接，从文本/图片节点拖拽即可快速创建下一环节

**🧠 智能化创作辅助**

- 集成Gemini 2.5进行提示词优化和智能建议
- 支持历史提示词复用，避免重复思考
- Sora2角色@提及功能，精准控制视频角色

**🔧 企业级工程能力**

- 零GPU要求，全部计算依赖云端API，轻量化部署
- 模块化架构设计，易于扩展新的AI模型和功能
- 完整的项目管理和资产治理体系

通过可视化工作流的方式，我们不仅降低了AI视频创作的门槛，更为创作者提供了一个专业、高效的创作平台。

## 📋 待办事项

为了实现"一站式解决AIGC创作问题"的目标，我们正在积极开发以下核心功能：

### 🔥 优先开发

- **Sora 2 完整接入**：实现完整的 Sora 2 模型集成和 API 调用  ✅
- **Sora 2 去水印功能**：提供智能水印移除和视频清理功能
- **视频拼接**：支持多段视频无缝拼接和过渡效果
- **视频剪辑**：添加视频裁剪、分割、合并基础编辑功能

### 🎬 视频创作增强

- **多模型视频生成**：接入 Runway、Pika、Gen-2 等主流视频模型
- **风格化视频**：支持不同艺术风格的视频生成
- **视频模板**：预置常用视频模板和效果
- **字幕自动生成**：AI 语音识别和时间轴对齐
- **背景音乐**：智能匹配和生成背景音乐

### 🎨 图像创作完善

- **多模型图像生成**：支持 Stable Diffusion、Midjourney、DALL-E 等
- **图像编辑器**：内置基础图像编辑和滤镜功能
- **风格转换**：图像风格迁移和艺术化处理
- **批量处理**：支持批量图像生成和处理

### 🎵 音频创作模块

- **AI 音乐生成**：根据情绪和场景生成背景音乐
- **音效库**：丰富的音效素材和智能匹配
- **语音合成**：多语言、多音色的 TTS 服务
- **音频编辑**：混音、降噪、音频效果处理

### 📝 文本创作辅助

- **剧本生成**：AI 辅助短视频脚本创作
- **文案优化**：智能标题和描述优化
- **多语言支持**：国际化内容和翻译功能

### 🔄 工作流优化

- **模板市场**：共享和下载创作模板
- **自动化规则**：设置复杂的自动化创作流程
- **批量生产**：一次设置批量产出内容
- **API 接口**：提供开放 API 供第三方集成

### 💼 商业化功能

- **团队协作**：多人协作编辑和权限管理
- **项目管理**：完整的项目生命周期管理
- **成本控制**：API 调用成本预估和预算管理
- **数据分析**：创作效果和用户行为分析

### 🎯 用户体验

- **移动端适配**：响应式设计和移动端优化
- **快捷操作**：更多快捷键和手势支持
- **智能推荐**：基于使用习惯的个性化推荐
- **教程体系**：内置教程和创作指导

---

## 🎯 核心功能

### 📋 项目管理

- **多项目支持**：创建和管理多个独立项目，每个项目包含独立的工作流
- **自动保存**：实时保存工作进度，防止数据丢失
- **项目历史**：追踪项目变更历史，支持版本回溯
- **协作功能**：支持团队成员共享和协作编辑项目

### 🎨 可视化画布编辑器

- **节点式工作流**：通过拖拽节点和连接线构建复杂的 AI 生成流程
- **智能连接**：自动类型匹配，确保节点间数据流向正确
- **多种节点类型**：
  - **文本节点**：输入提示词，支持 AI 优化建议
  - **图像节点**：文生图、图片上传、图片编辑
  - **视频节点**：图生视频、文生视频、视频合成
  - **组合节点**：将多个节点打包成可复用的组件
- **实时预览**：即时查看节点执行结果和生成内容

### 🤖 AI 模型集成

- **文本生成**：

  - Gemini 2.5 Flash / Pro 模型
  - 智能提示词优化和建议
  - 支持历史提示词复用
- **图像生成**：

  - Qwen Image Plus 模型
  - 多分辨率支持（16:9, 1:1, 9:16）
  - 批量生成（1-5张）
  - 图片编辑和后处理
- **视频生成**：

  - Sora 2 模型集成
  - 支持角色引用（@提及功能）
  - 多时长选项（10s, 15s）
  - 视频合成和剪辑

### 🛠️ 高级编辑功能

- **模板系统**：

  - 保存常用工作流为模板
  - 拖拽应用模板到画布
  - 模板管理和分类
- **资产库**：

  - 管理生成的图片、视频等素材
  - 支持素材复用和组合
  - 资产标签和搜索功能
- **智能辅助**：

  - 提示词自动补全和建议
  - 节点参数智能推荐
  - 连接类型自动匹配

### 🎬 内容生成工作流

- **文生图流程**：文本 → 图像生成
- **图生视频流程**：图像 → 视频生成
- **文生视频流程**：文本 → 视频直接生成
- **复合流程**：文本 → 图像 → 视频 → 后处理
- **并行处理**：支持多个节点同时执行，提高效率

### ⌨️ 快捷操作

- **键盘快捷键**：

  - `Cmd/Ctrl + G`：选中节点打组
  - `Cmd/Ctrl + Enter`：运行选中节点
  - `Cmd/Ctrl + C/V`：复制粘贴节点
  - `Delete`：删除选中元素
- **右键菜单**：快速访问常用功能
- **拖拽上传**：直接拖拽图片文件到节点
- **批量操作**：支持多选节点批量编辑

### 💾 数据管理

- **本地存储**：自动保存工作进度到浏览器
- **云端同步**：支持项目数据云端备份
- **导出功能**：
  - 导出图片、视频等生成内容
  - 导出工作流配置
  - 导出项目文档

## 🌟 特色亮点

### 🎯 用户体验

- **零学习成本**：直观的可视化界面，无需编程基础
- **实时反馈**：节点执行状态实时更新，进度条显示
- **智能提示**：根据上下文提供操作建议和参数推荐
- **响应式设计**：适配各种屏幕尺寸，支持移动端操作

### 🔧 技术特色

- **零 GPU 要求**：全部计算依赖云端 AI API，本地无硬件要求
- **高性能渲染**：基于 React Flow 的高效画布渲染
- **模块化架构**：易于扩展新的 AI 模型和功能
- **类型安全**：使用 TypeScript 确保代码质量

### 🚀 创新功能

- **智能连接**：自动识别节点类型兼容性，防止错误连接
- **组聚焦模式**：支持复杂工作流的分层管理和编辑
- **模板拖拽**：从侧边栏直接拖拽模板到画布快速创建
- **参数继承**：节点间自动传递和继承相关参数

## 🧱 架构概览

### 前端技术栈

- **React 18** + **TypeScript**：现代化的前端框架
- **React Flow**：强大的节点编辑器，支持复杂的可视化工作流
- **Mantine**：优雅的 UI 组件库
- **Zustand**：轻量级状态管理
- **Vite**：快速的构建工具

### 后端集成

- **Activepieces**：轻量级工作流编排引擎
- **第三方 AI API**：
  - OpenAI Sora 2（视频生成）
  - Gemini 2.5（文本生成）
  - Qwen Image Plus（图像生成）

### 数据存储

- **本地存储**：浏览器 localStorage 用于模板和缓存
- **云端存储**：S3/OSS 用于生成的媒体文件
- **项目数据**：支持云端同步和备份

## 🚀 快速开始

### 环境要求

- Node.js 18+
- pnpm 10.8.1+
- 现代浏览器（Chrome 90+, Firefox 88+, Safari 14+）

### 安装和运行

```bash
# 克隆项目
git clone https://github.com/anymouschina/TapCanvas.git
cd TapCanvas

# 安装依赖
pnpm install

# 启动开发服务器
pnpm dev:web

# 启动 API 服务器
pnpm dev:api
```

### 配置 AI API

1. 在项目根目录创建 `.env` 文件
2. 配置所需的 API 密钥：
   ```
   OPENAI_API_KEY=your_openai_api_key
   GOOGLE_API_KEY=your_google_api_key
   QWEN_API_KEY=your_qwen_api_key
   ```

## 📖 使用指南

### 创建第一个项目

1. 打开 TapCanvas 应用
2. 点击项目名称区域，输入项目名称
3. 从左侧面板拖拽 "文本" 节点到画布
4. 在文本节点中输入提示词
5. 连接其他节点构建工作流
6. 点击运行按钮开始生成

### 节点类型详解

#### 文本节点 (Text)

- 用于输入和优化提示词
- 支持 AI 智能建议
- 可连接到图像和视频生成节点

#### 图像节点 (Image)

- 支持文生图和图片上传
- 多种分辨率选择
- 批量生成功能

#### 视频节点 (Video)

- 图生视频和文生视频
- 支持多种时长
- 角色引用功能

### 工作流示例

#### 基础文生图

```
文本节点 → 图像节点
```

#### 图生视频

```
图像节点 → 视频节点
```

#### 复合工作流

```
文本节点 → 图像节点 → 视频节点
```

## 🔧 开发指南

### 项目结构

```
TapCanvas/
├── apps/
│   ├── web/              # 前端应用
│   └── api/              # API 服务
├── packages/
│   ├── cli/              # 命令行工具
│   ├── sdk/              # SDK 包
│   └── pieces/           # AI 模型集成
└── infra/
    └── activepieces/     # 后台编排服务
```

### 添加新的 AI 模型

1. 在 `packages/pieces` 中创建新的模型集成
2. 定义输入输出接口
3. 实现模型调用逻辑
4. 在前端添加对应的节点类型

### 自定义节点

参考 `apps/web/src/canvas/nodes/TaskNode.tsx` 创建自定义节点组件。

## 🤝 贡献指南

欢迎提交 Issue 和 Pull Request！

### 开发流程

1. Fork 项目
2. 创建功能分支
3. 提交更改
4. 发起 Pull Request

### 代码规范

- 使用 TypeScript
- 遵循 ESLint 规则
- 编写单元测试
- 更新文档

## 📄 许可证

MIT License

## 🔗 相关链接

- [GitHub 仓库](https://github.com/anymouschina/TapCanvas)
- [问题反馈](https://github.com/anymouschina/TapCanvas/issues)
- [功能建议](https://github.com/anymouschina/TapCanvas/discussions)

---

**让 AI 创作变得简单而强大！** 🎨✨

## 💬 交流社区

### 用户交流群

欢迎加入我们的用户交流群，与其他创作者一起分享经验、交流技巧/反馈问题/提交需求：

![交流群](assets/group.jpg)

### 联系作者

如果您有任何问题、建议或合作意向，欢迎直接联系作者：

![联系作者](assets/author.jpg)
